{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/_libs/__init__.py:3: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/indexes/base.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/indexes/datetimelike.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.period import Period\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/sparse/array.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/groupby.py:66: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import lib, groupby as libgroupby, Timestamp, NaT, iNaT\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/site-packages/pandas/io/parsers.py:43: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import pickle\n",
    "import os\n",
    "# import pymysql\n",
    "# import boto3\n",
    "#pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3fe70724f477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OCA_last_modified.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OCA_last_modified.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmod_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeffshamp/.conda/envs/bxd_etl/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unsupported pickle protocol: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPROTO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 3"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"OCA_last_modified.txt\"):\n",
    "    with open(\"OCA_last_modified.txt\", \"rb\") as fp:\n",
    "        mod_list = pickle.load(fp)\n",
    "else:\n",
    "    mod_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3cca1f2db45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mod_list' is not defined"
     ]
    }
   ],
   "source": [
    "mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nycourts.gov/LegacyPDFS/court-research/OCA-STAT-Act.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_base= \"https://www.nycourts.gov/\"\n",
    "link_path = \"LegacyPDFS/court-research/OCA-STAT-Act.csv\"\n",
    "link_url = link_base+link_path\n",
    "link_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_downloadable(link_url, mod_list):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    h = requests.head(link_url, allow_redirects=True)\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    if header[\"Last-Modified\"] in mod_list:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not downloadable or exists already.\n"
     ]
    }
   ],
   "source": [
    "if is_downloadable(link_url, mod_list):\n",
    "    r = requests.get(link_url)\n",
    "    last_mod = r.headers['Last-Modified']\n",
    "    mod_list.append(last_mod)\n",
    "    oca_data = pd.read_csv(io.StringIO(r.text))\n",
    "else: print(\"File not downloadable or exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mod_list:\n",
    "    with open(\"OCA_last_modified.txt\", \"wb\") as fp:\n",
    "        pickle.dump(mod_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wed, 06 Jan 2021 21:12:51 GMT',\n",
       " 'Mon, 08 Feb 2021 20:32:30 GMT',\n",
       " 'Tue, 06 Apr 2021 19:57:13 GMT']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scrape - Takes a while so use cautiously\n",
    "re_load = True\n",
    "if re_load:\n",
    "    r = requests.get(link_url)\n",
    "    oca_data = pd.read_csv(io.StringIO(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oca_main = oca_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from copy\n",
    "quick_load = True\n",
    "if quick_load:\n",
    "    oca_data = oca_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['county', 'court', 'arresting_agency', 'arrest_type', \n",
    "           'top_charge_at_arraignment', 'severity', 'weight', 'law',\n",
    "           'article_section', 'attempt_flag', 'docket_status',\n",
    "           'disposition_type', 'most_severe_sentence', 'article', 'section']\n",
    "bx_pd = [f\"nypd 04{i}\" for i in range(10)] + \\\n",
    "        [f\"nypd 05{i}\" for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic clean up and standardization \n",
    "oca_data = oca_data.applymap(lambda x:x.lower() if type(x) == str else x)\n",
    "oca_data.columns = oca_data.columns.str.replace(\" \", \"_\").str.replace(\".\", \"_\")\n",
    "oca_data.columns = oca_data.columns.str.lower()\n",
    "oca_data.article_section = oca_data.article_section.str.rstrip(\".\")\n",
    "oca_data.article_section = oca_data.article_section.str.replace(\"\\.\\.\", \".\")\n",
    "oca_data.drop(\"row_#\",axis=1, inplace=True)\n",
    "oca_data[[\"article\", \"section\"]] = oca_data.article_section.str.split(\".\", n=1,expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "oca_data = make_clean_precincts(oca_data)\n",
    "\n",
    "fel_weights = [x for x in oca_data.weight.unique() if \"f\" in x]\n",
    "fel_series = oca_data[oca_data.weight.isin(fel_weights)] \\\n",
    "    .article.apply(lambda x: make_felonies(x))\n",
    "vio_series = oca_data[oca_data.law.isin([\"vtl\"])] \\\n",
    "    .article.apply(lambda x: make_violations(x))\n",
    "bxd_category = pd.concat([fel_series, vio_series]) \\\n",
    "    .rename(\"bxd_category\")\n",
    "oca_data = oca_data.join(bxd_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Policy Peeps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What all do we want to track? Misdemeanors _other_ than 511s ?\n",
    "\n",
    "2) How to determine weapon charge from article/section/weight/law? Our data (I think) uses docket number info to determine this? No docket number in OCA STAT\n",
    "\n",
    "3) manslaughter vs assault (120/125) - do we want to delineate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapons = (\"|\").join([\"wea\", \"wpn\", \"wep\"])\n",
    "oca_data['weapon_charge'] = False\n",
    "oca_data.loc[(oca_data.top_charge_at_arraignment.str.contains(weapons)) &\n",
    "    (oca_data.weight != \"v\"), 'weapon_charge'] = True\n",
    "\n",
    "sex_charge = (\"|\").join([\"sex\", \"sx\"])\n",
    "oca_data[\"sex_charge\"] = False\n",
    "oca_data.loc[oca_data.top_charge_at_arraignment.str.contains(sex_charge),\n",
    "         \"sex_charge\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv = False\n",
    "if write_csv:\n",
    "    oca_data.to_csv(\"oca_data_clean_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article  top_charge_at_arraignment     \n",
       "120      aslt 3-w/int cause phys injury    9748\n",
       "155      petit larceny                     7150\n",
       "220      crim poss contrl subst-7th        4941\n",
       "215      crim contempt-2nd:disobey crt     4502\n",
       "0511     aggravated unlic oper veh-3rd     4174\n",
       "265      cpw-2nd: loaded firearm           3982\n",
       "1192     op mv while intoxicated 1         3273\n",
       "145      crim mis:intent damage proprty    3051\n",
       "120      menacing-2nd:weapon               2131\n",
       "         aslt w/int cause ph inj w/weap    1901\n",
       "Name: court, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oca_data.groupby(['article', 'top_charge_at_arraignment']).count()['court'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground to Cloud Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we wrestle with Jeff Bezos to get this information into our database programmatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) IAM user roles and permission?\n",
    "\n",
    "2) S3 bucket to store the root file?\n",
    "\n",
    "\n",
    "3) Action point: Use `pyscopg2` to connect to BxD Redshift instance\n",
    "    - Check on access keys via enviroment variables for python runtime.\n",
    "\n",
    "4) Action point: set up \"copy\" command to desired table from S3. This uses `psycopg2` as well. \n",
    "    - Check on auto commit functionality for this COPY command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible commands for automated upload to AWS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `boto3` to upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "file_path = \"<<-path_to_file->>\"\n",
    "bucket_name = \"<<-BxD_bucket->>\"\n",
    "\n",
    "def aws_session(region_name='us-east-1'):\n",
    "    return boto3.session.Session(\n",
    "        # use env variables to store AWS keys\n",
    "        # BxD might do something else with this. \n",
    "        # currently, this is a placeholder\n",
    "        aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "        aws_secret_access_key=os.getenv('AWS_ACCESS_KEY_SECRET'),\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "def upload_file_to_bucket(bucket_name, file_path):\n",
    "    session = aws_session()\n",
    "    s3_resource = session.resource('s3')\n",
    "    file_dir, file_name = os.path.split(file_path)\n",
    "\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "    bucket.upload_file(\n",
    "      Filename=file_path,\n",
    "      Key=file_name,\n",
    "      # ExtraArgs={'ACL': 'public-read'} probably don't want this \n",
    "      # Someone should know what the access control list should be (Jesus)\n",
    "    )\n",
    "    \n",
    "    # below is optional for confirmation that things when to the right place. \n",
    "    s3_url = f\"https://{bucket_name}.s3.amazonaws.com/{file_name}\"\n",
    "    return s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = aws_session()\n",
    "s3_bucket_url = upload_file_to_bucket(bucket_name, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `psycopg2` to copy csv file in S3 to BxD DB in Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def redshift():\n",
    "\n",
    "    conn = psycopg2.connect(dbname='**BxD_DB**',\n",
    "                            host='888888888888****.u.****.redshift.amazonaws.com',\n",
    "                            port='****', \n",
    "                            user='******', \n",
    "                            password='********')\n",
    "    cur = conn.cursor();\n",
    "    \n",
    "    # We can use env variables here as well with f-string literals if we want.\n",
    "    command = \"copy <<-OCA_table_name->> from \"\n",
    "    bucket_url = \"s3://<<-path_to_file_s3->>.csv \"\n",
    "    creds = \"credentials 'aws_access_key_id=<<-ID->>;aws_secret_access_key=<<-KEY->>' csv;\"\n",
    "    copy_command = command+bucket_url+creds\n",
    "    \n",
    "    # Begin your transaction\n",
    "    cur.execute(\"begin;\")\n",
    "\n",
    "    cur.execute(copy_command)\n",
    "    \n",
    "    # Commit your transaction if auto commits are not enabled\n",
    "    cur.execute(\"commit;\")\n",
    "    \n",
    "    # print(\"Copy executed fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
