{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import timeit\n",
    "from zipfile import ZipFile\n",
    "from StringIO import StringIO\n",
    "import urllib2\n",
    "import fnmatch\n",
    "import os\n",
    "#import boto3\n",
    "#import botocore\n",
    "import string\n",
    "from oca_utils.oca_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreTrial Data Extract\n",
    "\n",
    "This is the standalone file to extract the pretrial data from NYS OCA. \n",
    "This script can pull the data from OCA (release every 6 months) and upload it to the BxD Database for analytics use. \n",
    "\n",
    "This is written in python 2.7 for cross compatibility with the BxD ec2 instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_str = time.strftime(\"%Y-%m-%d\")\n",
    "link_url= \"http://www.nycourts.gov/\"\n",
    "link_subpath= \"LegacyPDFS/court-research/\"\n",
    "link_file= \"PretrialReleaseDataExtractWeb2020.zip\"\n",
    "link_url= link_url+link_subpath+link_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OCA STAT] - Vaild URL. Reading data.\n"
     ]
    }
   ],
   "source": [
    "# Try link for downloadable content - based on header information\n",
    "try:\n",
    "    is_downloadable(link_url)\n",
    "    print(\"[OCA STAT] - Vaild URL. Reading data.\")\n",
    "except requests.ConnectionError as exception:\n",
    "    print(\"[OCA STAT] - Not a valid URL.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick load\n",
    "\n",
    "set the `quick_load` to True, to skip the url request and simply read the most recent `.csv` extract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_load = False\n",
    "if quick_load:\n",
    "    pretrial = pd.read_csv(\"PretrialReleaseDataExtractWeb2020-revised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link works. Will extract from zip file on OCA site and read the output csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.81822896\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "r = urllib2.urlopen(link_url).read()\n",
    "file_ex = ZipFile(StringIO(r))\n",
    "file_ex.extractall()\n",
    "pattern = \"*-revisedWO.csv\"\n",
    "\n",
    "for root, dirs, files in os.walk(os.getcwd(),):\n",
    "    for filename in fnmatch.filter(files, pattern):\n",
    "        pretrial_csv = file_ex.open(filename)\n",
    "        pretrial = pd.read_csv(pretrial_csv)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tested on EC2\n",
    "\n",
    "The above extract does work on the. BxD ec2 instance as of 7/24/2021 around 12:00PM EST. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn our attention to transforming and cleaning up the data in the file. We will test several operations on both here and on ec2, so that they we are sure it can work in the cloud. Given that we have run into issues previously with instance timeout and memory kills, hopefully this approach will side-step those issues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on EC2\n",
    "\n",
    "This process take a large amount of time - 90 seconds on ec2 and close to a minute here. As much as it is desirable to have a consistent date format completed on the back-end, it might be worth exploring ThoughtSpot's ability to transform these date types if this code chunk becomes too large to complete on a t2.micro. The column `rearrest_date` is of the format \"Mar2021\" and need to be reassigned to datetime format. \n",
    "\n",
    "**OCA continues to change the file format so this may change.** They do seem to correct the date fields to a standard format, which is nice. `rearrest_date` may be correct in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial.columns = pretrial.columns.str.lower()\n",
    "pretrial.columns = pretrial.columns.str.replace(\" \", \"_\")\n",
    "pretrial.columns = pretrial.columns.str.replace(\"-\", \"_\")\n",
    "date_cols = [col for col in pretrial.columns if col.endswith('_date')]\n",
    "not_date_type = [\"rearrest_date\"]\n",
    "for col in date_cols:\n",
    "    if col in not_date_type:\n",
    "        pretrial[col] = pd.to_datetime(pretrial[col],format=\"%b%Y\") # fix Mar2020 format type\n",
    "    pretrial[col] = pd.to_datetime(pretrial[col],errors='coerce') # assign datetime to all else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_columns = [col for col in pretrial.columns if col.startswith(\"top_\")]\n",
    "top_charges = [col for col in pretrial if col.startswith(\"top_charge_at\") and not col.endswith(\"_ind\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_strings = pretrial[[\"top_arrest_article_section\", \"top_charge_at_arrest\",\n",
    "                        \"top_charge_at_conviction\",\"top_conviction_article_section\",\n",
    "                        \"top_charge_at_arraign\", \"top_arraign_article_section\",]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blank top_xx_article_section\n",
    "\n",
    "1) \\_arrest: What to do this theese? Leave blank or convert to arraignment charges. There are only 2457 (1.3% of total data)\n",
    "\n",
    "2) \\_arraign: Same question but less often. only 0.76% (1406 total) in the data set. \n",
    "\n",
    "3) \\_conviction: Much dirter entries. Some are NaN (expected) but the formatting is odd. some are dates, many dashes and letters that don't exist in the other article_section columns. The very sketchy ones look to be very very rare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tested on ec2 \n",
    "lowering works for all columns in this method. loop is better than .applymap <br>\n",
    "- changed oca_stat.py to reflect this new learning. As of 7/26/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to complete string manipulation:  31.1439847946\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "for col in pretrial:\n",
    "    if pretrial[col].dtype == \"O\":\n",
    "        pretrial[col] = pretrial[col].str.lower()\n",
    "        pretrial[col] = pretrial[col].str.replace(\"-\",\"\")\n",
    "        pretrial[col] = pretrial[col].str.replace(\"\\(\", \"\").str.replace(\"\\)\",\"\")\n",
    "\n",
    "        \n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print \"time to complete string manipulation: \", elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Columns - article, section, subsection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 105 columns in this data set, that's a lot. We have made more in other data set to separate out article and section for top charge at arraignment. It's helpful in ThoughtSpot to have multiple ways to filter so that TS isn't filtering everything via the same column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'top_arrest_article_section', u'top_charge_at_arrest',\n",
       "       u'top_charge_at_conviction', u'top_conviction_article_section',\n",
       "       u'top_charge_at_arraign', u'top_arraign_article_section'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_strings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffshamp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jeffshamp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n",
      "/Users/jeffshamp/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "arraign = pretrial[\"top_charge_at_arraign\"].str.extract(r'((\\d+) (\\w+) (\\w+))') \\\n",
    "    .rename(columns = {0:\"full\", 1:\"section\",2:\"subsection\",3:\"charge\"})\n",
    "arrest = pretrial[\"top_charge_at_arrest\"].str.extract(r'((\\d+) (\\w+) (\\w+))') \\\n",
    "    .rename(columns = {0:\"full\", 1:\"section\",2:\"subsection\",3:\"charge\"})\n",
    "convict = pretrial[\"top_charge_at_conviction\"].str.extract(r'((\\d+) (\\w+) (\\w+.{3}))') \\\n",
    "    .rename(columns = {0:\"full\", 1:\"section\",2:\"subsection\",3:\"charge\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial[\"arraign_subsection_bxd\"] = arraign['subsection']\n",
    "pretrial[\"arrest_subsection_bxd\"] = arrest['subsection']\n",
    "pretrial[\"conviction_subsection_bxd\"] = convict['subsection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pretrial.top_charge_weight_at_arraign.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial.arraign_subsection_bxd = pretrial.arraign_subsection_bxd.apply(lambda x:clean_subsection(x, weights))\n",
    "pretrial.arrest_subsection_bxd = pretrial.arrest_subsection_bxd.apply(lambda x:clean_subsection(x, weights))\n",
    "pretrial.conviction_subsection_bxd = pretrial.conviction_subsection_bxd.apply(lambda x:clean_subsection(x, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial[[\"arraign_article_bxd\", \"arraign_section_bxd\"]] = \\\n",
    "            pretrial.top_arraign_article_section.str.split(\".\",n=1,expand=True)\n",
    "pretrial[[\"arrest_article_bxd\", \"arrest_section_bxd\"]] = \\\n",
    "            pretrial.top_arraign_article_section.str.split(\".\",n=1,expand=True)\n",
    "pretrial[[\"conviction_article_bxd\", \"conviction_section_bxd\"]] = \\\n",
    "            pretrial.top_arraign_article_section.str.split(\".\",n=1,expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clean = False\n",
    "if save_clean:\n",
    "    pretrial.to_csv(\"pretrial_clean.csv\")\n",
    "load_clean = False\n",
    "if load_clean: # fix date type inference\n",
    "    pretrial = pd.read_csv(\"pretrial_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two strange judge name types. \"Office, Clerk's\" and \"judege/jho/hearing examiner, visiting\". These types make up ~3000 judge name entries, so it's fairly common in the dataset. They usully show up in upstate counties as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name\n",
       "onondaga       1016\n",
       "oneida          439\n",
       "ontario         268\n",
       "steuben         202\n",
       "cayuga          140\n",
       "albany          127\n",
       "cattaraugus      93\n",
       "warren           90\n",
       "oswego           59\n",
       "bronx            57\n",
       "erie             56\n",
       "clinton          50\n",
       "ulster           25\n",
       "niagara          20\n",
       "westchester      15\n",
       "Name: court_name, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial[pretrial.judge_name.str.contains(\"office|hearing\")] \\\n",
    "    .groupby(\"county_name\").count()[\"court_name\"] \\\n",
    "    .sort_values(ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count              184118\n",
       "unique                594\n",
       "top       graf,_alfred_c.\n",
       "freq                 2987\n",
       "Name: judge_name, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial.judge_name.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure if we care about the ratio of cash to credit in bail amounts, but it does seem to be used in a weird way. Bascially, no one uses credit even if it is less in amount than cash. \n",
    "\n",
    "73% of bail is not paid, 14% is paid in cash, 11% bond, and 1% is credit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrial['cash_credit_ratio_bail'] = pretrial.first_bail_set_cash/pretrial.first_bail_set_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "bail_set = pretrial[(pretrial.first_bail_set_cash.isnull() == False) |\n",
    "        (pretrial.first_bail_set_credit.isnull() == False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN       73.352360\n",
       "cash      14.073418\n",
       "bond      11.557261\n",
       "credit     1.016960\n",
       "Name: bail_made_indicator, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial[(pretrial.first_bail_set_cash.isnull() == False) |\n",
    "        (pretrial.first_bail_set_credit.isnull() == False)] \\\n",
    "            .bail_made_indicator.value_counts(dropna=False)/bail_set*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Columns - bail made amount - dollar bail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New column for bail made amount. If bail is paid, then this column determines the method of payment and records that amount. If bail is set at 5000:cash, 1000:credit, and 6000:bond, and a bond is taken, then 6000 will be recorded in `bail_made_amount_bxd`.\n",
    "\n",
    "`dollar_bail_bxd` tracks all the `first_bail_set_cash` values for those equal to 1\\$. The cash bail set field seesm to dicated the dollar bail cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_ser = pretrial[pretrial.bail_made_indicator == \"cash\"].first_bail_set_cash\n",
    "credit_ser = pretrial[pretrial.bail_made_indicator == \"credit\"].first_bail_set_credit\n",
    "bond_ser = pretrial[pretrial.bail_made_indicator == \"bond\"].first_insurance_company_bail_bond\n",
    "null_ser = pretrial[pretrial.bail_made_indicator.isnull()].bail_made_indicator\n",
    "bail_amount = pd.concat([cash_ser, credit_ser, bond_ser, null_ser]) \\\n",
    "        .rename(\"bail_made_amount_bxd\")\n",
    "pretrial = pretrial.join(bail_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial['dollar_bail_bxd'] = False\n",
    "pretrial.loc[(pretrial.first_bail_set_cash == 1.0),\n",
    "             'dollar_bail_bxd'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New columns - prior conviction - pending arrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [col for col in pretrial.columns if col.startswith(\"prior\")]\n",
    "pending = [col for col in pretrial.columns if col.startswith(\"pend_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrial[\"priors_sum_bxd\"] = pretrial[priors].sum(axis=1)\n",
    "pretrial[\"pending_arrest_sum_bxd\"] = pretrial[pending].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[OCA STAT] - Saving to s3 {}\" \\\n",
    "          .format(time.strftime(\"%Y-%m-%d:%H:%M:%S\")))\n",
    "########### Upload to S3 ######################\n",
    "    \n",
    "tgt_bucket = 'bxdgoogletransformed'\n",
    "tgt_csv = 'pretrial'\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "f = open(tgt_csv+'.csv', 'rb')\n",
    "try:\n",
    "    s3.Bucket(tgt_bucket).put_object(\n",
    "                Key='extract_'+today_str+'/'+tgt_csv+'.csv',\n",
    "                ServerSideEncryption='aws:kms',\n",
    "                StorageClass='STANDARD_IA',\n",
    "                Body=f)\n",
    "except:\n",
    "    print(\"[OCA STAT] - s3 resource error\")\n",
    "\n",
    "print(\"[OCA STAT] - Done {}\" \\\n",
    "      .format(time.strftime(\"%Y-%m-%d %H:%M:%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
